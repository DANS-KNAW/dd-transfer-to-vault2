{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"dd-transfer-to-vault \u00b6 Processes dataset version exports for inclusion in the DANS Data Vault SYNOPSIS \u00b6 dd-transfer-to-vault { server | check }","title":"Synopsis"},{"location":"#dd-transfer-to-vault","text":"Processes dataset version exports for inclusion in the DANS Data Vault","title":"dd-transfer-to-vault"},{"location":"#synopsis","text":"dd-transfer-to-vault { server | check }","title":"SYNOPSIS"},{"location":"arch/","text":"DANS Data Station Architecture \u00b6 This module is a component in the DANS Data Station Architecture .","title":"\u21d2 DANS Data Station Architecture"},{"location":"arch/#dans-data-station-architecture","text":"This module is a component in the DANS Data Station Architecture .","title":"DANS Data Station Architecture"},{"location":"description/","text":"DESCRIPTION \u00b6 Overview \u00b6 This service is responsible for taking dataset version exports (DVE for short), cataloging them and transferring them to the DANS data vault. If the dataset version export is the first version of a dataset, an NBN persistent identifier is minted for the dataset and registered in the NBN database. For more information about the context of this service, see the Data Station architecture overview . Interfaces \u00b6 Provided \u00b6 Inbox \u00b6 Protocol type : Shared filesystem Internal or external : internal Purpose : to receive DVEs from the Data Stations and other services Admin console \u00b6 Protocol type : HTTP Internal or external : internal Purpose : application monitoring and management Consumed \u00b6 Data Vault Catalog \u00b6 Protocol type : HTTP Internal or external : internal Purpose : to maintain information about the datasets and their versions that are stored in the DANS data vault NBN Database \u00b6 Protocol type : HTTP Internal or external : external Purpose : to mint and register NBN persistent identifiers for datasets Data Vault import inbox \u00b6 Protocol type : Shared filesystem Internal or external : internal Purpose : to import DVEs into the DANS data vault Data Vault API \u00b6 Protocol type : HTTP Internal or external : internal Purpose : to issue commands to the DANS data vault and retrieve information from it Processing \u00b6 This service is best viewed as a processing pipeline for DVEs. It connects a source that produces DVEs to a target DANS Data Vault Storage Root , which stores the DVEs as OCFL object versions. A source can be a Data Station or a Vault as a Service client. The service takes care of cataloging the DVEs and ensuring that the dataset is resolvable via the NBN persistent identifier. It attempts to do this in an efficient way, by processing multiple DVEs in parallel, while ensuring that the order of the dataset version exports is preserved. Furthermore, the service will attempt to resume processing of DVEs that were left unfinished in the event of a crash or restart. Inbox \u00b6 The inbox is a directory into which DVEs are dropped. When a DVE is detected the inbox will determine what the NBN of the target dataset is. DVEs for the same dataset version are processed in order, but DVEs for different dataset versions can be processed in parallel, except for the transfer to the vault (see below). Validation \u00b6 The first step in the processing pipeline is to validate the DVE. Currently, the only layout that is supported is the [bagpack] layout. If the DVE is not a bagpack, it will be rejected. Any other DVEs for the same dataset version will be blocked from processing until the problem is resolved. Metadata extraction \u00b6 The next step is to extract the metadata from the DVE and to create or update the dataset version in the DANS data vault catalog. The main source of metadata is the metadata/oai-ore.jsonld file in the DVE. NBN registration \u00b6 After the Vault Catalog has been updated, the NBN persistent identifier is minted and scheduled for registration in the NBN database. This is done in a separate background thread which uses a database table as a queue, so that the registration can be retried in case of a restart or crash. Transfer to vault and layer management \u00b6 Finally, the DVE is extracted to the current DANS data vault import inbox batch for this instance of dd-transfer-to-vault . If the size of the batch exceeds a configured threshold, the service will do two things: Check if a new layer is needed. If so, it will issue a command to the DANS data vault to create a new layer. Issue a command to the DANS data vault to import the current batch of DVEs. This step is executed on a single dedicated thread, so that determining the size of the batch can be done reliably. The import command will return a tracking URL which can be used to monitor the progress of the import. A confirmation of archiving task is scheduled to check the status of the import and to confirm that the DVE has been archived in the DANS data vault. Confirmation of archiving \u00b6 This step is also performed in a separate background thread, similar to the NBN registration. When dd-data-vault confirms that the DVE has been archived, the Vault Catalog is updated to mark the dataset version as archived.","title":"Description"},{"location":"description/#description","text":"","title":"DESCRIPTION"},{"location":"description/#overview","text":"This service is responsible for taking dataset version exports (DVE for short), cataloging them and transferring them to the DANS data vault. If the dataset version export is the first version of a dataset, an NBN persistent identifier is minted for the dataset and registered in the NBN database. For more information about the context of this service, see the Data Station architecture overview .","title":"Overview"},{"location":"description/#interfaces","text":"","title":"Interfaces"},{"location":"description/#provided","text":"","title":"Provided"},{"location":"description/#inbox","text":"Protocol type : Shared filesystem Internal or external : internal Purpose : to receive DVEs from the Data Stations and other services","title":"Inbox"},{"location":"description/#admin-console","text":"Protocol type : HTTP Internal or external : internal Purpose : application monitoring and management","title":"Admin console"},{"location":"description/#consumed","text":"","title":"Consumed"},{"location":"description/#data-vault-catalog","text":"Protocol type : HTTP Internal or external : internal Purpose : to maintain information about the datasets and their versions that are stored in the DANS data vault","title":"Data Vault Catalog"},{"location":"description/#nbn-database","text":"Protocol type : HTTP Internal or external : external Purpose : to mint and register NBN persistent identifiers for datasets","title":"NBN Database"},{"location":"description/#data-vault-import-inbox","text":"Protocol type : Shared filesystem Internal or external : internal Purpose : to import DVEs into the DANS data vault","title":"Data Vault import inbox"},{"location":"description/#data-vault-api","text":"Protocol type : HTTP Internal or external : internal Purpose : to issue commands to the DANS data vault and retrieve information from it","title":"Data Vault API"},{"location":"description/#processing","text":"This service is best viewed as a processing pipeline for DVEs. It connects a source that produces DVEs to a target DANS Data Vault Storage Root , which stores the DVEs as OCFL object versions. A source can be a Data Station or a Vault as a Service client. The service takes care of cataloging the DVEs and ensuring that the dataset is resolvable via the NBN persistent identifier. It attempts to do this in an efficient way, by processing multiple DVEs in parallel, while ensuring that the order of the dataset version exports is preserved. Furthermore, the service will attempt to resume processing of DVEs that were left unfinished in the event of a crash or restart.","title":"Processing"},{"location":"description/#inbox_1","text":"The inbox is a directory into which DVEs are dropped. When a DVE is detected the inbox will determine what the NBN of the target dataset is. DVEs for the same dataset version are processed in order, but DVEs for different dataset versions can be processed in parallel, except for the transfer to the vault (see below).","title":"Inbox"},{"location":"description/#validation","text":"The first step in the processing pipeline is to validate the DVE. Currently, the only layout that is supported is the [bagpack] layout. If the DVE is not a bagpack, it will be rejected. Any other DVEs for the same dataset version will be blocked from processing until the problem is resolved.","title":"Validation"},{"location":"description/#metadata-extraction","text":"The next step is to extract the metadata from the DVE and to create or update the dataset version in the DANS data vault catalog. The main source of metadata is the metadata/oai-ore.jsonld file in the DVE.","title":"Metadata extraction"},{"location":"description/#nbn-registration","text":"After the Vault Catalog has been updated, the NBN persistent identifier is minted and scheduled for registration in the NBN database. This is done in a separate background thread which uses a database table as a queue, so that the registration can be retried in case of a restart or crash.","title":"NBN registration"},{"location":"description/#transfer-to-vault-and-layer-management","text":"Finally, the DVE is extracted to the current DANS data vault import inbox batch for this instance of dd-transfer-to-vault . If the size of the batch exceeds a configured threshold, the service will do two things: Check if a new layer is needed. If so, it will issue a command to the DANS data vault to create a new layer. Issue a command to the DANS data vault to import the current batch of DVEs. This step is executed on a single dedicated thread, so that determining the size of the batch can be done reliably. The import command will return a tracking URL which can be used to monitor the progress of the import. A confirmation of archiving task is scheduled to check the status of the import and to confirm that the DVE has been archived in the DANS data vault.","title":"Transfer to vault and layer management"},{"location":"description/#confirmation-of-archiving","text":"This step is also performed in a separate background thread, similar to the NBN registration. When dd-data-vault confirms that the DVE has been archived, the Vault Catalog is updated to mark the dataset version as archived.","title":"Confirmation of archiving"},{"location":"installation/","text":"INSTALLATION \u00b6 Currently, this project is built as an RPM package for OSes compatible with RHEL8 and later. The RPM will install the binaries to /opt/dans.knaw.nl/dd-transfer-to-vault and the configuration files to /etc/opt/dans.knaw.nl/dd-transfer-to-vault . For installation on systems that do no support RPM and/or systemd: Build the tarball (see next section). Extract it to some location on your system, for example /opt/dans.knaw.nl/dd-transfer-to-vault . Start the service with the following command /opt/dans.knaw.nl/dd-transfer-to-vault/bin/dd-transfer-to-vault server /opt/dans.knaw.nl/dd-transfer-to-vault/cfg/config.yml BUILDING FROM SOURCE \u00b6 Prerequisites: Java 17 or higher Maven 3.6.3 or higher RPM Steps: git clone https://github.com/DANS-KNAW/dd-transfer-to-vault.git cd dd-transfer-to-vault mvn clean install If the rpm executable is found at /usr/local/bin/rpm , the build profile that includes the RPM packaging will be activated. If rpm is available, but at a different path, then activate it by using Maven's -P switch: mvn -Pprm install . Alternatively, to build the tarball execute: mvn clean install assembly:single","title":"Installation & building"},{"location":"installation/#installation","text":"Currently, this project is built as an RPM package for OSes compatible with RHEL8 and later. The RPM will install the binaries to /opt/dans.knaw.nl/dd-transfer-to-vault and the configuration files to /etc/opt/dans.knaw.nl/dd-transfer-to-vault . For installation on systems that do no support RPM and/or systemd: Build the tarball (see next section). Extract it to some location on your system, for example /opt/dans.knaw.nl/dd-transfer-to-vault . Start the service with the following command /opt/dans.knaw.nl/dd-transfer-to-vault/bin/dd-transfer-to-vault server /opt/dans.knaw.nl/dd-transfer-to-vault/cfg/config.yml","title":"INSTALLATION"},{"location":"installation/#building-from-source","text":"Prerequisites: Java 17 or higher Maven 3.6.3 or higher RPM Steps: git clone https://github.com/DANS-KNAW/dd-transfer-to-vault.git cd dd-transfer-to-vault mvn clean install If the rpm executable is found at /usr/local/bin/rpm , the build profile that includes the RPM packaging will be activated. If rpm is available, but at a different path, then activate it by using Maven's -P switch: mvn -Pprm install . Alternatively, to build the tarball execute: mvn clean install assembly:single","title":"BUILDING FROM SOURCE"}]}